{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_Orientacao_Academica_LoP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EXnFYbxV75Np",
        "WUBAPloS58yP",
        "TjeHFDBfwV5w",
        "oPh-k3-fR_zP",
        "AEJF9bZMSZpk",
        "B4rJ_jPviRsl",
        "DmuLGrPKFv1c",
        "PGR1IWltjEKS",
        "7bW-MMNpvndY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilsonrodrigues/Projeto_Orientacao_Academica_LoP/blob/main/Projeto_Orientacao_Academica_LoP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_vdAfc21u86"
      },
      "source": [
        "Por @vilsonrodrigues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLxXyebtnjM-"
      },
      "source": [
        "\n",
        "\n",
        "# <center>Projeto de Orientação Acadêmica do LoP\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULCWX6-dwLgg"
      },
      "source": [
        "<img src='https://ufrn.br/resources/documentos/identidadevisual/logotipo/logotipo_flat.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tX7zYBx5Sd"
      },
      "source": [
        "## Parte I - Apresentação do Problema\n",
        "### [1. Apresentação do Problema](#apresentacao)\n",
        "## Parte II - Preparativos Iniciais\n",
        "### [1. Bibliotecas](#bibliotecas)\n",
        "### [2. Classe](#classe)\n",
        "### [3. Funções](#funcoes)\n",
        "### [4. Leitura da Base](#leiturabase)\n",
        "## Parte III - Desenvolvimento\n",
        "### [1. Entendimento de Negócio](#negocio)\n",
        "### [2. Entendimento de Dados](#enten_dados)\n",
        "### [3. Preparação de Dados](#preparo)\n",
        "### [4. Métricas de Avaliação](#metricas)\n",
        "### [5. Modelagem](#modelagem)\n",
        "### [6. Avaliação de Modelo](#avaliacao)\n",
        "### [7. Conclusão e Recomendações](#conclusao)\n",
        "### [8. Implantação de Modelos](#implantacao)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwf-rhVr2Wvj"
      },
      "source": [
        "# Parte I - Apresentação do Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhu64Xadx9yH"
      },
      "source": [
        "### Meta\n",
        "\n",
        "### Fonte dos Dados\n",
        "\n",
        "### Referência\n",
        "Hands On: Machine Learning with Scikit-Learning e Tensor Flow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW86HnPh3ka-"
      },
      "source": [
        "# Parte II - Preparativos Iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkhuxXT_3vQv"
      },
      "source": [
        "## 1. Bibliotecas\n",
        "<a id='bibliotecas'></a>\n",
        "#### [1.1 Instalações](#instalacao)\n",
        "#### [1.2 Importações](#importacao)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuOEB2A10Rah"
      },
      "source": [
        "### 1.1. Instalação\n",
        "<a id='instalacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HXuie4y43tN"
      },
      "source": [
        "!pip install pandas -U\n",
        "!pip install scikit-learn -U\n",
        "!pip install numpy -U\n",
        "!pip install joblib==0.14.1\n",
        "!conda install xgboost -c conda-forge --yes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_S-Ua3YeLmS"
      },
      "source": [
        "### 1.2. Importação\n",
        "<a id='importacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDskXdweAA6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Persistência em disco\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "#Visualização\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Transformadores e Modelador\n",
        "from sklearn.pipeline          import Pipeline\n",
        "from sklearn.preprocessing     import StandardScaler\n",
        "from sklearn.base              import BaseEstimator, TransformerMixin\n",
        "\n",
        "#Selecao de modelo\n",
        "from sklearn.model_selection   import train_test_split\n",
        "from sklearn.model_selection   import KFold\n",
        "from sklearn.model_selection   import cross_val_score\n",
        "from sklearn.model_selection   import GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "#Metricas\n",
        "from sklearn.metrics           import classification_report\n",
        "from sklearn.metrics           import confusion_matrix\n",
        "from sklearn.metrics           import make_scorer\n",
        "from sklearn.metrics           import accuracy_score\n",
        "from sklearn.metrics           import f1_score\n",
        "from sklearn.metrics           import recall_score\n",
        "from sklearn.metrics           import precision_score\n",
        "\n",
        "#Classificadores\n",
        "from sklearn.ensemble          import RandomForestClassifier\n",
        "from xgboost                   import XGBClassifier\n",
        "from sklearn.tree              import DecisionTreeClassifier\n",
        "from sklearn.neighbors         import KNeighborsClassifier\n",
        "from sklearn.naive_bayes       import GaussianNB\n",
        "from sklearn.svm               import SVC\n",
        "from sklearn.neural_network    import MLPClassifier\n",
        "\n",
        "#modo não-perturbe\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jauxgHcS9nOM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXnFYbxV75Np"
      },
      "source": [
        "##2. Classe\n",
        "<a id='classe'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4WG5ZVa9Abp"
      },
      "source": [
        "Classe para realizar x-ação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sfmYXZd8MuV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGHrISEE_B3_"
      },
      "source": [
        "##3. Funções\n",
        "<a id='funcoes'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8k5ZIKXkEJ_"
      },
      "source": [
        "Função de leitura de arquivos txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgY9TfQvkCSh"
      },
      "source": [
        "def read_txt(path):\n",
        "  with open(path,'r') as file:\n",
        "    return file.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aRrmnVXkm82"
      },
      "source": [
        "Função de consulta no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BueEgapukKO8"
      },
      "source": [
        "def lop_consult(url):\n",
        "  http = urllib3.PoolManager()\n",
        "  req = http.request('GET',url)\n",
        "  if req.status == 200:\n",
        "    return pd.read_json(req.data, orient = 'RECORDS', encoding = 'utf-8').copy()\n",
        "  else: \n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_SDIJpLayi"
      },
      "source": [
        "Função para obter todas as classes do LoP a partir de uma lista de professores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL2uxEK0X3M"
      },
      "source": [
        "def lop_class(df_teacher = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_teacher se torna desnecessário fazer a requisição de todas os professores, e evitando fazer varias consultas\n",
        "  #Dataframe onde será armazenado todas as turmas\n",
        "  df_class = pd.DataFrame()\n",
        "  if df_teacher.empty == True:\n",
        "    #Formação da url de consulta para saber os professores cadastrados no LoP\n",
        "    url_teacher = endpoint_teacher + key\n",
        "    #Realizando a consulta no LoP\n",
        "    df_teacher = lop_consult(url_teacher)#id, email, name\n",
        "  #O laço faz uma varredura das turmas de cada professor e por fim armazena em um dataframe de turmas\n",
        "  for id_teacher in df_teacher.id:\n",
        "    #O LoP.v2 foi desenvolvido em 2019, então temos que capturar as turmas entre 2019 e o ano atual\n",
        "    current_year = datetime.now().year\n",
        "    for year in range(2019, current_year + 1):\n",
        "      #Por fim precisamos do semestre que deve ser 1 ou 2\n",
        "      for semester in range(1,3): \n",
        "        #Url de consulta de classes\n",
        "        url_class = endpoint_class + id_teacher + '?year=' + str(year) + '&semester=' + str(semester) + '&key=' + key \n",
        "        #Dataframe provisório necessário para capturar o tamanho e saber quantas turmas esse professor tem que estar associado\n",
        "        df_prov = lop_consult(url_class)\n",
        "        #Inserindo o id do professor no dataframe de turmas\n",
        "        df_prov['id_teacher'] = id_teacher\n",
        "        #Adicionando turmas conforme novas consultas\n",
        "        df_class = df_class.append(df_prov, ignore_index=True).copy()#id, name, code, year, semester, id_teacher\n",
        "  #Renomeando colunas com nomes semelhantes em todos os DF\n",
        "  df_class.rename(columns={'id':'id_class','name':'name_class'}, inplace = True)\n",
        "  return df_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVs1I-sChMaS"
      },
      "source": [
        "Função para obter todas as submissões a partir de uma lista de turmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqp3HGeFlKC"
      },
      "source": [
        "def lop_submission(df_class = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_class se torna desnecessário fazer a requisição de todas as turmas usando a função lop_class()\n",
        "  #Dataframe onde serão armazenados todas as submissões \n",
        "  df_submission = pd.DataFrame()  \n",
        "  if df_class.empty == True:\n",
        "    df_class = lop_class()  \n",
        "  #Obtem todas as submissões da lista de turmas passadas\n",
        "  for id_class in df_class.id_class:\n",
        "    #Url da consulta as submissões\n",
        "    url_submission = endpoint_submission + id_class + '/submission?key=' + key\n",
        "    #Dataframe provisório que vai armazenar o resultado da consulta\n",
        "    df_prov = lop_consult(url_submission)\n",
        "    #Inserindo o id_class no dataframe de consultas\n",
        "    df_prov['id_class'] = id_class\n",
        "    #Adicionando submissões conforme consultas\n",
        "    df_submission = df_submission.append(df_prov, ignore_index=True).copy()\n",
        "  return df_submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPYJVKnjA8jn"
      },
      "source": [
        "Função para obter dados das questões cadastradas no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZu9CVgtA70_"
      },
      "source": [
        "def lop_question():\n",
        "  url_question = endpoint_question + key\n",
        "  df_lop_question = lop_consult(url_question)\n",
        "  df_lop_question.rename(columns = {'id':'id_question','title':'question'}, inplace = True)\n",
        "  return df_lop_question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBdYtwVOXdZ"
      },
      "source": [
        "Função que transforma os dados das questões extraídas do LoP, assim podemos saber a dificuldade de uma questão, que pode estar associada a uma ou mais listas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3pLjztaOWzR"
      },
      "source": [
        "def question_data(df_question = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_question se torna desnecessário fazer a requisição de todas as turmas usando a função lop_question()\n",
        "  #Dataframes onde serão armazenados todas as questões transformadas\n",
        "  df_list_data = pd.DataFrame()  \n",
        "  df_tag_data = pd.DataFrame()  \n",
        "  df_question_data = pd.DataFrame()  \n",
        "  if df_question.empty == True:\n",
        "    df_question = lop_question()\n",
        "  for question,lists,tags,difficulty in zip(df_question.question,df_question.lists,df_question.tags,df_question.difficulty):\n",
        "    #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "    df_prov_lists  = pd.DataFrame(json.loads(str(lists).replace(\"'\",'\"')))\n",
        "    #df_prov_lists.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_lists['question'] = question\n",
        "    df_prov_lists['difficulty'] = difficulty\n",
        "    df_list_data = df_list_data.append(df_prov_lists, ignore_index = True).copy()\n",
        "    #Extraindo as tags, que vão dizer o conteudo associado\n",
        "    df_prov_tags = pd.DataFrame(json.loads(str(tags).replace(\"'\",'\"'))).T\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_tags['question'] = question    \n",
        "    df_tag_data = df_tag_data.append(df_prov_tags, ignore_index = True).copy()\n",
        "  \n",
        "  df_list_data.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "  #df_list_data['difficulty'] = df_list_data['difficulty'].astype('int')\n",
        "  columns_tags = ['question']\n",
        "  for i in range(len(df_tag_data.columns)-1): columns_tags.append('tag'+str(i+1))\n",
        "  df_tag_data.columns = columns_tags\n",
        "  return pd.merge(df_list_data, df_tag_data, on = 'question', how = 'outer').fillna(0).copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU4EIevUPzqH"
      },
      "source": [
        "Função para avaliar a perfomance por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B0Kx6BKPfK6"
      },
      "source": [
        "def performance_list(df_submission):  \n",
        "  #Essa função necessita receber as submissões de uma turma ---------- depois podemos incrementar essa função ao ter uma turma associada e agrupar por elas\n",
        "  #Me traz as porcentagens maximas de acerto por questão\n",
        "  df_performance_list = df_submission.groupby(['user','list','question'])['hitPercentage'].max().reset_index()\n",
        "  #Soma as porcentagens de uma lista unica\n",
        "  df_performance_list = df_performance_list.groupby(['user','list'])['hitPercentage'].sum().reset_index()\n",
        "  #Renomeando para melhorar entendimento\n",
        "  df_performance_list.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
        "  #Usando a função de dados de questão para ter informações sobre que questões estão associadas a lista\n",
        "  df_question_data = question_data()\n",
        "  #Agrupa por lista e questão para ter apenas uma questão de cada, a operação não importa muito, apenas existe para completar o agrupamento --------- pode ser uma boa trocar por drop_duplicates\n",
        "  df_question_data = df_question_data.groupby(['list','question'])['id_list'].count().reset_index()\n",
        "  #Conta quantas questões tem por lista\n",
        "  df_question_data = df_question_data.groupby(['list'])['question'].count().reset_index()\n",
        "  #Renomeando lista\n",
        "  df_question_data.rename(columns={'question':'totalQuestionsList'}, inplace = True)\n",
        "  #Merge\n",
        "  df_performance_list = df_performance_list.merge(df_question_data, on = 'list')\n",
        "  #Média de acerto por lista\n",
        "  df_performance_list['mediaList'] = df_performance_list['totalHitPercentage'] / df_performance_list['totalQuestionsList']\n",
        "  return df_performance_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7lq048T5cvn"
      },
      "source": [
        "Função do gráfico de barras que, por lista, faz a contagem de quem fez mais e menos de 70% da lista. Necessita de passar a performance do aluno por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btbzysrv5cF6"
      },
      "source": [
        "def graph_more_less_70_list_class(df_performance_list):\n",
        "  #Aqui eu conto, por lista, quantos tiraram mais de 70% de acerto\n",
        "  df_more70 = df_performance_list[df_performance_list['mediaList'] >= 70.0].groupby('list')['mediaList'].count().reset_index(name='more70')\n",
        "  #E nesse conta quantos tiveram menos de 70%\n",
        "  df_less70 = df_performance_list[df_performance_list['mediaList'] < 70.0].groupby('list')['mediaList'].count().reset_index(name='less70')\n",
        "  #Aqui junta ambos os dataframes, usando o outer, que, se por acaso não tiver uma ocorrência de uma lista em um dos dataframes, mesmo assim eles vão ser adicionados, é união dos conjuntos\n",
        "  df_less_more_70 = pd.merge(df_more70, df_less70, on = 'list', how = 'outer')\n",
        "  #E, se caso acontecer a situação de um não existir, substituimos o nan por 0\n",
        "  df_less_more_70.replace(np.NaN, 0, inplace = True)\n",
        "  return df_less_more_70.to_json('df_less_more_70.json',force_ascii=False, orient='records') #############3 por hora essa função tamebm esta realizando downlaod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibCTW9blyG0b"
      },
      "source": [
        "Função do grafico de distribuição de notas por lista. Necessita da performance do  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmX_TtzQALyR"
      },
      "source": [
        "def graph_distribution_notes_list(df_performance_list):\n",
        "  #Agrupa por lista, e conta as ocorrências\n",
        "  return df_performance_list.groupby('list')['mediaList'].apply(lambda group: group.values.tolist()).to_json('df_distribuition_notes_list.json',force_ascii=False,orient='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnKD95YdJV6Z"
      },
      "source": [
        "Não mexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0MOygqJXNa"
      },
      "source": [
        "#df_teste.groupby('user')[['list','mediaList']].apply(lambda group: group.values.tolist()).to_json(force_ascii=False).replace('{\"','{\"students\":[{\"user\":\"').replace(\":[[\",',\"lists\":[{\"list\":').replace(\":]],\",',\"lists\":}]').replace(']],\"','}],\"user\":\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaGpFuLmJC70"
      },
      "source": [
        "Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhAmMuJ0A_Yk"
      },
      "source": [
        "turma = ['66baea8b-9ee0-4297-a218-a76a35e9dca4']\n",
        "df_subs = lop_submission(pd.DataFrame(turma, columns = ['id_class']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BUSGqrsC9BC"
      },
      "source": [
        "**Por hora descondirem essa função**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gXGYd0w_GRp"
      },
      "source": [
        "'''\n",
        "def avaliar_modelos(df, hyperparameters):\n",
        "\n",
        "  #Dicionários\n",
        "  model_param_disciplinas = {}\n",
        "  best_acc_disciplinas = {}\n",
        "  scoring_disciplinas = {}\n",
        "  #feature_importances_disciplinas = {}\n",
        "\n",
        "  #Seleciona o codigo de cada disciplina no dataframe, --alteravel--\n",
        "  lista_disciplinas = df[\"disciplina\"].unique()  \n",
        "\n",
        "  #Verifica se esta vazio\n",
        "  if lista_disciplinas is None:\n",
        "\t  return None\n",
        "\n",
        "  #Convertendo categorias do target de string para numerico (0,1)\n",
        "  df[\"situacao_categoria\"] = pd.Categorical(df[\"situacao\"]).codes\n",
        "\n",
        "  #Pipeline para transformar em categoria e verificar melhores parametros\n",
        "  pipeline_transform = Pipeline(steps = [('num_pipeline', NumericalTransformer()),\n",
        "                                         ('fs',SelectKBest(chi2)),\n",
        "                                         ('sc',StandardScaler()),\n",
        "                                         ('clf',XGBClassifier())\n",
        "                               ])\n",
        "\n",
        "  #Grid para testar todos os parâmetros                               \n",
        "  grid_search = GridSearchCV(\n",
        "                          estimator = pipeline_transform, \n",
        "                          param_grid = hyperparameters,\n",
        "                          cv= 5,\n",
        "                          scoring = {'Accuracy': make_scorer(accuracy_score)},\n",
        "                          #scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score), \"F1\":\"f1\", \"Recall\":\"recall\", \"Precision\":\"precision\"},\n",
        "                          return_train_score=True,\n",
        "                          n_jobs=-1,#indica o numero de processos em paralelo, -1 significa usar todos\n",
        "                          refit='Accuracy')\n",
        "\n",
        "\n",
        "  #itera sobre a lista de disciplinas\n",
        "  for disciplina in lista_disciplinas:\n",
        "    data_iter = df.loc[df[\"disciplina\"].str.contains(disciplina),:]\n",
        "    \n",
        "    #Treinando Grid\n",
        "    best_model = grid_search.fit(data_iter.drop(columns = [\"disciplina\",\"situacao_categoria\"]), data_iter[\"situacao_categoria\"])\n",
        " \n",
        "    #Extraindo informações do treino\n",
        "    param_modelo = best_model.best_params_\n",
        "    model_param_disciplinas[disciplina] = param_modelo['clf']\n",
        "    best_acc_disciplinas[disciplina] = best_model.best_score_\n",
        "\n",
        "    #Resultado de metricas\n",
        "    result = pd.DataFrame(best_model.cv_results_)\n",
        "    result = result[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy','rank_test_Accuracy']].copy()\n",
        "    result[\"std_ratio\"] = result.std_test_Accuracy/result.std_train_Accuracy\n",
        "    result = result.sort_values(by=\"rank_test_Accuracy\",ascending=True)    \n",
        "    scoring_disciplinas[disciplina] = result.iloc[0,:]\n",
        "\n",
        "    #Características mais importantes\n",
        "    #feature_importances_disciplinas[disciplina] = grid.best_estimator_.feature_importances_\n",
        "    \n",
        "    #Salvando modelo\n",
        "    joblib.dump(best_model, 'modelo_' + disciplina + '.pkl')\n",
        "\n",
        "\n",
        "  #Transformando o dicionário para Dataframe\n",
        "  df_best_acc = pd.DataFrame.from_dict(best_acc_disciplinas, orient=\"index\")\n",
        "  df_best_acc.columns = [\"accuracy\"]\n",
        "  df_scor_disc = pd.DataFrame.from_dict(scoring_disciplinas, orient=\"index\")\n",
        "\n",
        "  #Concatenando DataFrames\n",
        "  df_relatorio = pd.concat([df_best_acc, df_scor_disc], axis=1, sort=False)\n",
        "\n",
        "  return (df_relatorio,model_param_disciplinas)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1-lyVuizPA"
      },
      "source": [
        "##4. Leitura da Base\n",
        "<a id='leiturabase'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVMECL1jJAxf"
      },
      "source": [
        "### Foi projetado para ter 4 tipos de consultas\n",
        "\n",
        "* A primeira é para receber dados dos professores que estão resgistrados no sistema\n",
        "\n",
        "* A segunda é para receber dados das turmas que estão registradas no sistema\n",
        "\n",
        "* A terceira é para receber dados das submissões que estão registradas no sistema\n",
        "\n",
        "* A quarta é para receber dados das questões que estão registradas no sistema\n",
        "\n",
        "As consultas vão ser tornando acumulativas, com a segunda dependendo de dados da primeira, e a terceira dependendo de dados da primeira e segunda para o preenchimento da url de consulta. Todas as consultas dependem da key de acesso\n",
        "\n",
        "Na consulta da class possui as depedências de: \n",
        "1. id_teacher, que é o id de um professor\n",
        "2. year, que é o ano da turma \n",
        "3. semester, que é o semestre (1 ou 2) da turma\n",
        "\n",
        "E na consulta de submission necessita do:\n",
        "1. id_class, que é o id de uma turma.\n",
        "\n",
        "Já a consulta de question e do teacher necessita apenas da key\n",
        "\n",
        "As consultas serão feitas via protocolo HTTP usando o método Get e irão receber um JSON dos dados do LoP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2rVvODlKxFz"
      },
      "source": [
        "### Estrutra das funções e suas dependências\n",
        "\n",
        "Funções de coleta e transformações de dados \n",
        "\n",
        "- lop_class(), lop_question()\n",
        "--- lop_submission()\n",
        "------ question_data()\n",
        "--------- performance_list()\n",
        "------------ graph_more_less_70_list_class()\n",
        "------------ graph_distribution_notes_list()\n",
        "\n",
        "Funções de treinamento de modelos de Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLS4lxbbQwTo"
      },
      "source": [
        "Leitura de endpoints e key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syfUfm4xQz82"
      },
      "source": [
        "key = read_txt('key.txt')\n",
        "endpoint_teacher = read_txt('endpoint_teacher.txt')\n",
        "endpoint_class = read_txt('endpoint_class.txt')\n",
        "endpoint_submission = read_txt('endpoint_submission.txt')\n",
        "endpoint_question = read_txt('endpoint_question.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8EDgPstkv9e"
      },
      "source": [
        "Consultando submissões a partir de uma lista de turmas\n",
        "\n",
        "Vou pegar uma turma aleatoria afim de montar uma consulta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCJzm_YXlwJo"
      },
      "source": [
        "turma = ['b5413cd7-4f61-4241-aad8-23740bab604f']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBVlqgzZmWN1"
      },
      "source": [
        "Necessita passar como DataFrame, então eu vou construir nesse formato exibido abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEUmG7bRl-jn",
        "outputId": "c12a5992-80b6-4ce5-ed1e-aa79f746a40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pd.DataFrame(['b5413cd7-4f61-4241-aad8-23740bab604f'], columns = ['id_class']).to_json(orient='records')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[{\"id_class\":\"b5413cd7-4f61-4241-aad8-23740bab604f\"}]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuA_GGParVFn"
      },
      "source": [
        "**A partir daqui ainda vai sofrer alterações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hra4Ho4IC0Xu"
      },
      "source": [
        "#Parte III - Desenvolvimento\n",
        "<a id='enten_dados'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n4co8p2EeaU"
      },
      "source": [
        "## 1. Entendimento de Dados\n",
        "<a id='enten_dados'></a>\n",
        "\n",
        "### [1.1 Descrição de Dados](#descricao)\n",
        "### [1.2 Qualidade de Dados](#qualidade)\n",
        "### [1.3 Exploração de Dados](#exploracao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEVg1VCYEhUd"
      },
      "source": [
        "###1.1 Descrição de Dados\n",
        "<a id='descricao'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1HZgOL4pQfu"
      },
      "source": [
        "#### <center>Dataframe Submissões\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyy |\n",
        "| 2020.6 | yyyy | xxx |\n",
        "\n",
        "#### <center>Dataframe Resultados em LOP\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyyyy |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do datafrane dos professores - Consulta embutida em lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. email</b> Email do professor\n",
        "\n",
        "<b>3. name_teacher</b> Nome do professor\n",
        "\n",
        "--- \n",
        "\n",
        "####Descrição do dataframe das turmas - lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. id_class</b> ID da turma\n",
        "\n",
        "<b>3. name_class</b> Nome da turma\n",
        "\n",
        "<b>4. code</b> Código de acesso a turma no LoP\n",
        "\n",
        "<b>5. year</b> Ano em que a turma foi cadastrada\n",
        "\n",
        "<b>6. semester</b> Semestre em que a turma foi cadastrada\n",
        "\n",
        "---\n",
        "####Descrição dos dataframe de Submissão - lop_submission()\n",
        "\n",
        "\n",
        "<b>1. environment</b> Tipo de máquina\n",
        "\n",
        "<b>2. hitPercentage</b> Porcentagem de acerto na questão\n",
        "\n",
        "<b>3. language</b> Linguagem de programação usada\n",
        "\n",
        "<b>4. char_change_number</b> Número de caracteres alterados\n",
        "\n",
        "<b>5. timeConsuming</b> Tempo que passou na questão\n",
        "\n",
        "<b>6. createdAt</b> Data e hora da submissão\n",
        "\n",
        "<b>7. user</b> Nome e matrícula do aluno\n",
        "\n",
        "<b>8. question</b> Nome da questão\n",
        "\n",
        "<b>9. list</b> Nome da lista\n",
        "\n",
        "<b>10. test</b> Nome da prova\n",
        "\n",
        "<b>11. id_class</b> ID da turma em que o aluno está associado nessa submissão\n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do dataframe das questões do LoP - lop_question()\n",
        "\n",
        "\n",
        "<b>1. id_questao</b> ID da questão\n",
        "\n",
        "<b>2. question</b> Nome da questão\n",
        "\n",
        "<b>3. difficulty </b> Nível de dificuldade da questão (1-5)\n",
        "\n",
        "<b>4. tags </b> Esse campo vem com um json que contem os assuntos em que essa questão está associada\n",
        "\n",
        "<b>5. lists </b> Esse campo vem com um json que contem as listas que a questão está associada \n",
        "\n",
        "<b>6. tests</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do dataframe de dados das questões - question_data()\n",
        "\n",
        "\n",
        "<b>1. id_list</b> ID da lista\n",
        "\n",
        "<b>2. list</b> Nome da lista\n",
        "\n",
        "<b>3. question </b> Nome da questão\n",
        "\n",
        "<b>4. difficulty </b> Nível de dificuldade da questão (1-5)\n",
        "\n",
        "<b>5. tags </b> Em cada coluna com nome tag, terá um conteúdo associado a ela\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "####Descrição do dataframe de performance por lista - performance_list()\n",
        "\n",
        "\n",
        "<b>1. user</b> Nome e matrícula do aluno\n",
        "\n",
        "<b>2. list</b> Nome da lista\n",
        "\n",
        "<b>3. totalHitPercentage </b> Soma de todos acertos de questões únicas\n",
        "\n",
        "<b>4. totalQuestionsList </b> Número de questões por lista\n",
        "\n",
        "<b>5. mediaList</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlpXzVJfPKL-"
      },
      "source": [
        "df.select_dtypes(include=['int64','float64']).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXMGrCW2t9ys"
      },
      "source": [
        "profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBAPloS58yP"
      },
      "source": [
        "###1.2 Qualidade dos dados\n",
        "<a id='qualidade'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVjvZp435e2C"
      },
      "source": [
        "Plotando correlação entre os dados númericos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnuyvSq5j_-"
      },
      "source": [
        "corr = df.corr()\n",
        "corr = corr.style.background_gradient(cmap='Blues')\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23glKTxPo98x"
      },
      "source": [
        "Falar um pouco da correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjeHFDBfwV5w"
      },
      "source": [
        "###1.3 Exploração de Dados\n",
        "<a id='exploracao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgJ2UcFYoad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9S1wjjCuu89"
      },
      "source": [
        "##2. Preparação de Dados\n",
        "<a id='preparo'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuPFoSjMvBNL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPh-k3-fR_zP"
      },
      "source": [
        "##3. Métricas de Avaliação\n",
        "<a id='metricas'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXy0iQtzn75"
      },
      "source": [
        "\n",
        "#### <center>Métricas de Avaliação:\n",
        "| Regressores | Classificadores\n",
        "| --- | --- |\n",
        "| <center>RMSE| <center>Matriz de Confusão |\n",
        "| <center>MAE| <center>Acurácia |\n",
        "| <center>R2| <center>Precisão / Recall / F1 |\n",
        "| <center>R2 Ajustado| <center>AUC |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEJF9bZMSZpk"
      },
      "source": [
        "##4. Modelagem\n",
        "<a id='#modelagem'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4zVFwlFZUjt"
      },
      "source": [
        "Dicionário com hiper-parâmetros dos algoritmos preditivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeVjRatU2xs"
      },
      "source": [
        "hyperparameters = [\n",
        "                  {\"clf\":[RandomForestClassifier()],\n",
        "                  \"clf__n_estimators\": [100],\n",
        "                  \"clf__criterion\": [\"entropy\"],\n",
        "                  \"clf__max_leaf_nodes\": [64],\n",
        "                  \"clf__random_state\": [42],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,30]\n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[KNeighborsClassifier()],\n",
        "                  \"clf__n_neighbors\":[5,9,11],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,30]                 \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[SVC()],\n",
        "                  \"clf__kernel\":[\"sigmoid\",'rbf'],\n",
        "                  \"clf__degree\":[3,4],\n",
        "                  \"clf__gamma\":[0.1,0.5,1],\n",
        "                  \"clf__C\":[0.001,1,2],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,25,31] \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[GaussianNB()]\n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[MLPClassifier()],\n",
        "                  \"clf__hidden_layer_sizes\": [(64,),(128,)],\n",
        "                  \"clf__activation\": [\"logistic\"],\n",
        "                  \"clf__solver\": [\"sgd\"],\n",
        "                  \"clf__max_iter\": [500],\n",
        "                  \"clf__early_stopping\":[True],\n",
        "                  \"clf__n_iter_no_change\":[20],\n",
        "                  \"clf__validation_fraction\":[0.20], \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[XGBClassifier()],\n",
        "                  \"clf__n_estimators\": [50,100],\n",
        "                  \"clf__max_depth\": [4,6],\n",
        "                  \"clf__learning_rate\": [0.001, 0.01,0.1],\n",
        "                  \"clf__random_state\": [42],\n",
        "                  \"clf__subsample\": [1.0],\n",
        "                  \"clf__colsample_bytree\": [1.0],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[5,8,15,25,31]\n",
        "                  }\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4rJ_jPviRsl"
      },
      "source": [
        "##5. Avaliação dos Modelos\n",
        "<a id='avaliacao'></a>\n",
        "\n",
        "### [5.1 Chamada da Função](#chamada)\n",
        "### [5.2 Teste de Modelo](#teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxO10k-KJnZq"
      },
      "source": [
        "###5.1 Chamada da Função\n",
        "<a id='chamada'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a54d338IldVz"
      },
      "source": [
        "(df_relatorio, model_param_disciplinas) = avaliar_modelos(df, hyperparameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgZO6QU0YH1"
      },
      "source": [
        "df_relatorio.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCcRXPWv0eAL"
      },
      "source": [
        "model_param_disciplinas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmuLGrPKFv1c"
      },
      "source": [
        "###5.2 Teste de Modelo\n",
        "<a id='teste'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GMVe3bUsvS"
      },
      "source": [
        "Importando Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchPDLEsUvt5"
      },
      "source": [
        "modelo_teste = joblib.load('modelo_.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lcNJROjYtth"
      },
      "source": [
        "Aplicando a transformação no teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgKRWABoBfVb"
      },
      "source": [
        "num_transf = NumericalTransformer()\n",
        "df_teste = model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jte7qW39ZR8V"
      },
      "source": [
        "df_teste.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Qb55Di8IkC"
      },
      "source": [
        "Realizando teste de um modelo, prevendo probabilidade de ser aprovado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLooF6-vaQ7C"
      },
      "source": [
        "df_teste.iloc[42,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zusMtVzabUZ"
      },
      "source": [
        "df_teste.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTg3Zgf-YrEm"
      },
      "source": [
        "modelo_teste.predict(df_teste.iloc[42,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGR1IWltjEKS"
      },
      "source": [
        "##6. Conclusão e Recomendações\n",
        "<a id='conclusao'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-JlYcDhvmg4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bW-MMNpvndY"
      },
      "source": [
        "##7. Implantação de Modelos\n",
        "<a id='implantacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bcNUiIDvzTt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}