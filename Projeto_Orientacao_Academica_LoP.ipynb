{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Projeto_Orientacao_Academica_LoP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WHD15qbBEJTd",
        "sLsWhEZ2CIr_",
        "WUBAPloS58yP",
        "TjeHFDBfwV5w",
        "oPh-k3-fR_zP",
        "AEJF9bZMSZpk",
        "B4rJ_jPviRsl",
        "DmuLGrPKFv1c",
        "PGR1IWltjEKS"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilsonrodrigues/Projeto_Orientacao_Academica_LoP/blob/main/Projeto_Orientacao_Academica_LoP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_vdAfc21u86"
      },
      "source": [
        "Por @vilsonrodrigues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLxXyebtnjM-"
      },
      "source": [
        "\n",
        "\n",
        "# <center>Projeto de Orientação Acadêmica do LoP\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULCWX6-dwLgg"
      },
      "source": [
        "<img src='https://ufrn.br/resources/documentos/identidadevisual/logotipo/logotipo_flat.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tX7zYBx5Sd"
      },
      "source": [
        "## Parte I - Apresentação do Problema\n",
        "### [1. Apresentação do Problema](#apresentacao)\n",
        "## Parte II - Preparativos Iniciais\n",
        "### [1. Bibliotecas](#bibliotecas)\n",
        "### [2. Classe](#classe)\n",
        "### [3. Funções](#funcoes)\n",
        "### [4. Leitura da Base](#leiturabase)\n",
        "## Parte III - Desenvolvimento\n",
        "### [1. Entendimento de Negócio](#negocio)\n",
        "### [2. Entendimento de Dados](#enten_dados)\n",
        "### [3. Preparação de Dados](#preparo)\n",
        "### [4. Métricas de Avaliação](#metricas)\n",
        "### [5. Modelagem](#modelagem)\n",
        "### [6. Avaliação de Modelo](#avaliacao)\n",
        "### [7. Conclusão e Recomendações](#conclusao)\n",
        "### [8. Implantação de Modelos](#implantacao)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwf-rhVr2Wvj"
      },
      "source": [
        "# Parte I - Apresentação do Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhu64Xadx9yH"
      },
      "source": [
        "### Meta\n",
        "\n",
        "### Fonte dos Dados\n",
        "\n",
        "### Referência\n",
        "Hands On: Machine Learning with Scikit-Learning e Tensor Flow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW86HnPh3ka-"
      },
      "source": [
        "# Parte II - Preparativos Iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkhuxXT_3vQv"
      },
      "source": [
        "## 1. Bibliotecas\n",
        "<a id='bibliotecas'></a>\n",
        "#### [1.1 Instalações](#instalacao)\n",
        "#### [1.2 Importações](#importacao)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuOEB2A10Rah"
      },
      "source": [
        "### 1.1. Instalação\n",
        "<a id='instalacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HXuie4y43tN"
      },
      "source": [
        "!pip install pandas -U\n",
        "!pip install scikit-learn -U\n",
        "!pip install numpy -U\n",
        "!pip install joblib==0.14.1\n",
        "!conda install xgboost -c conda-forge --yes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_S-Ua3YeLmS"
      },
      "source": [
        "### 1.2. Importação\n",
        "<a id='importacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDskXdweAA6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Persistência em disco\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "#Visualização\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Transformadores e Modelador\n",
        "from sklearn.pipeline          import Pipeline\n",
        "from sklearn.preprocessing     import StandardScaler\n",
        "from sklearn.base              import BaseEstimator, TransformerMixin\n",
        "\n",
        "#Selecao de modelo\n",
        "from sklearn.model_selection   import train_test_split\n",
        "from sklearn.model_selection   import KFold\n",
        "from sklearn.model_selection   import cross_val_score\n",
        "from sklearn.model_selection   import GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "#Metricas\n",
        "from sklearn.metrics           import classification_report\n",
        "from sklearn.metrics           import confusion_matrix\n",
        "from sklearn.metrics           import make_scorer\n",
        "from sklearn.metrics           import accuracy_score\n",
        "from sklearn.metrics           import f1_score\n",
        "from sklearn.metrics           import recall_score\n",
        "from sklearn.metrics           import precision_score\n",
        "\n",
        "#Classificadores\n",
        "from sklearn.ensemble          import RandomForestClassifier\n",
        "from xgboost                   import XGBClassifier\n",
        "from sklearn.tree              import DecisionTreeClassifier\n",
        "from sklearn.neighbors         import KNeighborsClassifier\n",
        "from sklearn.naive_bayes       import GaussianNB\n",
        "from sklearn.svm               import SVC\n",
        "from sklearn.neural_network    import MLPClassifier\n",
        "\n",
        "#modo não-perturbe\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jauxgHcS9nOM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHD15qbBEJTd"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4WG5ZVa9Abp"
      },
      "source": [
        "Classe para a API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sfmYXZd8MuV"
      },
      "source": [
        "class lop(pandas,numpy,json,urllib3):\n",
        "  import pandas as pd \n",
        "  def __init__(self):\n",
        "    super().__init__(self)\n",
        "    pass\n",
        "\n",
        "  #Função de leitura de arquivos txt\n",
        "  def read_txt(path):\n",
        "    with open(path,'r') as file:\n",
        "      return file.read()\n",
        "\n",
        "  #Função de consulta no LoP\n",
        "  def lop_consult(url):\n",
        "    http = urllib3.PoolManager()\n",
        "    req = http.request('GET',url)\n",
        "    if req.status == 200:\n",
        "      return pd.read_json(req.data, orient = 'RECORDS', encoding = 'utf-8').copy()\n",
        "    else: \n",
        "      return False\n",
        "\n",
        "  #Função para obter todas as classes do LoP a partir de uma lista de professores\n",
        "  def lop_class(df_teacher = pd.DataFrame()):\n",
        "    #Essa função se passar por cópia o df_teacher se torna desnecessário fazer a requisição de todas os professores, e evitando fazer varias consultas\n",
        "    #Dataframe onde será armazenado todas as turmas\n",
        "    df_class = pd.DataFrame()\n",
        "    if df_teacher.empty == True:\n",
        "      #Formação da url de consulta para saber os professores cadastrados no LoP\n",
        "      url_teacher = endpoint_teacher + key\n",
        "      #Realizando a consulta no LoP\n",
        "      df_teacher = lop_consult(url_teacher)#id, email, name\n",
        "    #O laço faz uma varredura das turmas de cada professor e por fim armazena em um dataframe de turmas\n",
        "    for id_teacher in df_teacher['id']:\n",
        "      #O LoP.v2 foi desenvolvido em 2019, então temos que capturar as turmas entre 2019 e o ano atual\n",
        "      current_year = datetime.now().year\n",
        "      for year in range(2019, current_year + 1):\n",
        "        #Por fim precisamos do semestre que deve ser 1 ou 2\n",
        "        for semester in range(1,3): \n",
        "          #Url de consulta de classes\n",
        "          url_class = endpoint_class + id_teacher + '?year=' + str(year) + '&semester=' + str(semester) + '&key=' + key \n",
        "          #Dataframe provisório necessário para capturar o tamanho e saber quantas turmas esse professor tem que estar associado\n",
        "          df_prov = lop_consult(url_class)\n",
        "          #Inserindo o id do professor no dataframe de turmas\n",
        "          df_prov['id_teacher'] = id_teacher\n",
        "          #Adicionando turmas conforme novas consultas\n",
        "          df_class = df_class.append(df_prov, ignore_index=True).copy()#id, name, code, year, semester, id_teacher\n",
        "    #Renomeando colunas com nomes semelhantes em todos os DF\n",
        "    df_class.rename(columns={'id':'id_class','name':'name_class'}, inplace = True)\n",
        "    return df_class\n",
        "\n",
        "  #Função para obter todas as submissões a partir de uma lista de turmas\n",
        "  def lop_submission(df_class = pd.DataFrame()):\n",
        "    #Essa função se passar por cópia o df_class se torna desnecessário fazer a requisição de todas as turmas usando a função lop_class()\n",
        "    #Dataframe onde serão armazenados todas as submissões \n",
        "    df_submission = pd.DataFrame()  \n",
        "    if df_class.empty == True:\n",
        "      df_class = lop_class()  \n",
        "    #Obtem todas as submissões da lista de turmas passadas\n",
        "    for id_class in df_class['id_class']:\n",
        "      #Url da consulta as submissões\n",
        "      url_submission = endpoint_submission + id_class + '/submission?key=' + key\n",
        "      #Dataframe provisório que vai armazenar o resultado da consulta\n",
        "      df_prov = lop_consult(url_submission)\n",
        "      #Inserindo o id_class no dataframe de consultas\n",
        "      df_prov['id_class'] = id_class\n",
        "      #Adicionando submissões conforme consultas\n",
        "      df_submission = df_submission.append(df_prov, ignore_index=True).copy()\n",
        "    #Campo user trás matricula e o nome do usuário, vamos separar em 2 colunas distintas\n",
        "    df_submission[['user','registration']] = df_submission['user'].str.split('-',expand=True)\n",
        "    return df_submission\n",
        "\n",
        "  #Função para obter dados das questões cadastradas no LoP\n",
        "  def lop_question():\n",
        "    url_question = endpoint_question + key\n",
        "    df_lop_question = lop_consult(url_question)\n",
        "    df_lop_question.rename(columns = {'id':'id_question','title':'question'}, inplace = True)\n",
        "    return df_lop_question\n",
        "  \n",
        "  #Função que transforma os dados das questões extraídas do LoP, assim podemos saber a dificuldade de uma questão, que pode estar associada a uma ou mais listas\n",
        "  def question_data(df_question = pd.DataFrame()):\n",
        "    #Essa função se passar por cópia o df_question se torna desnecessário fazer a requisição de todas as turmas usando a função lop_question()\n",
        "    #Dataframes onde serão armazenados todas as questões transformadas\n",
        "    df_list_data = pd.DataFrame()  \n",
        "    df_tag_data = pd.DataFrame()  \n",
        "    df_question_data = pd.DataFrame()  \n",
        "    if df_question.empty == True:\n",
        "      df_question = lop_question()\n",
        "    for question,lists,tags,difficulty in zip(df_question['question'],df_question['lists'],df_question['tags'],df_question['difficulty']):\n",
        "      #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "      df_prov_lists  = pd.DataFrame(json.loads(str(lists).replace(\"'\",'\"')))\n",
        "      #df_prov_lists.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "      #Inserindo a questão associada\n",
        "      df_prov_lists['question'] = question\n",
        "      df_prov_lists['difficulty'] = difficulty\n",
        "      df_list_data = df_list_data.append(df_prov_lists, ignore_index = True).copy()\n",
        "      #Extraindo as tags, que vão dizer o conteudo associado\n",
        "      df_prov_tags = pd.DataFrame(json.loads(str(tags).replace(\"'\",'\"'))).T\n",
        "      #Inserindo a questão associada\n",
        "      df_prov_tags['question'] = question    \n",
        "      df_tag_data = df_tag_data.append(df_prov_tags, ignore_index = True).copy()\n",
        "    df_list_data.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "    #df_list_data['difficulty'] = df_list_data['difficulty'].astype('int')\n",
        "    columns_tags = ['question']\n",
        "    for i in range(len(df_tag_data.columns)-1): columns_tags.append('tag'+str(i+1))\n",
        "    df_tag_data.columns = columns_tags\n",
        "    return pd.merge(df_list_data, df_tag_data, on = 'question', how = 'outer').fillna(0).copy()\n",
        "\n",
        "  #Função para avaliar a perfomance por lista\n",
        "  def performance_list(df_submission, df_question_data = pd.DataFrame()):  \n",
        "    #Essa função necessita receber as submissões de uma turma ---------- depois podemos incrementar essa função ao ter uma turma associada e agrupar por elas\n",
        "    #Me traz as porcentagens maximas de acerto por questão\n",
        "    df_performance_list = df_submission.groupby(['user','registration','list','question'])['hitPercentage'].max().reset_index()\n",
        "    #Soma as porcentagens de uma lista unica\n",
        "    df_performance_list = df_performance_list.groupby(['user','registration','list'])['hitPercentage'].sum().reset_index()\n",
        "    #Renomeando para melhorar entendimento\n",
        "    df_performance_list.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
        "    if df_question_data.empty == True:\n",
        "      #Usando a função de dados de questão para ter informações sobre que questões estão associadas a lista\n",
        "      df_question_data = question_data()\n",
        "    #Agrupa por lista e questão para ter apenas uma questão de cada, a operação não importa muito, apenas existe para completar o agrupamento --------- pode ser uma boa trocar por drop_duplicates\n",
        "    df_question_data = df_question_data.groupby(['list','question'])['id_list'].count().reset_index()\n",
        "    #Conta quantas questões tem por lista\n",
        "    df_question_data = df_question_data.groupby(['list'])['question'].count().reset_index()\n",
        "    #Renomeando lista\n",
        "    df_question_data.rename(columns={'question':'totalQuestionsList'}, inplace = True)\n",
        "    #Merge\n",
        "    df_performance_list = df_performance_list.merge(df_question_data, on = 'list')\n",
        "    #Média de acerto por lista\n",
        "    df_performance_list['mediaList'] = df_performance_list['totalHitPercentage'] / df_performance_list['totalQuestionsList']\n",
        "    return df_performance_list\n",
        "  \n",
        "  #Função do gráfico de barras que, por lista, faz a contagem de quem fez mais e menos de 70% da lista. Necessita de passar a performance do aluno por lista\n",
        "  def graph_more_less_70_list_class(df_performance_list):\n",
        "    #Aqui eu conto, por lista, quantos tiraram mais de 70% de acerto\n",
        "    df_more70 = df_performance_list[df_performance_list['mediaList'] >= 70.0].groupby('list')['mediaList'].count().reset_index(name='more70')\n",
        "    #E nesse conta quantos tiveram menos de 70%\n",
        "    df_less70 = df_performance_list[df_performance_list['mediaList'] < 70.0].groupby('list')['mediaList'].count().reset_index(name='less70')\n",
        "    #Aqui junta ambos os dataframes, usando o outer, que, se por acaso não tiver uma ocorrência de uma lista em um dos dataframes, mesmo assim eles vão ser adicionados, é união dos conjuntos\n",
        "    df_less_more_70 = pd.merge(df_more70, df_less70, on = 'list', how = 'outer')\n",
        "    #E, se caso acontecer a situação de um não existir, substituimos o nan por 0\n",
        "    df_less_more_70.replace(np.NaN, 0, inplace = True)\n",
        "    return df_less_more_70.to_json(force_ascii=False, orient='records') ############# por hora essa função tamebm esta realizando downlaod\n",
        "\n",
        "  #Função do gráfico de barras que, por aluno, calcula a média do aluno por lista e agrupa todas as listas e notas em um campo só\n",
        "  def graph_performance_student_list(df_performance_list):\n",
        "    #Usando dummies para transformar cada lista em uma coluna. O Dummies vai inserir 1 em cada ocorrencia\n",
        "    df_performance_list = pd.get_dummies(df_performance_list,columns=['list'],prefix='',prefix_sep='')\n",
        "    #Cria um dataframe provisório\n",
        "    df_prov = pd.DataFrame()\n",
        "    #Campo do valor que irei inserir\n",
        "    df_mediaList = df_performance_list['mediaList']\n",
        "    #Apagando colunas desnecessárias\n",
        "    df_performance_list = df_performance_list.drop(columns=['totalHitPercentage','totalQuestionsList','mediaList'])\n",
        "    #Iterando sobre todo as submissões\n",
        "    for i in range(len(df_performance_list.user)):\n",
        "      #Substituindo o 1 do dummies pela média da lista\n",
        "      df_prov = df_prov.append(df_performance_list.iloc[i,:].replace(1,df_mediaList[i]))\n",
        "    #Agrupando para todas as linhas se tornarem apenas 1 ocorrência de cada aluno\n",
        "    df_prov = df_prov.groupby(['user','registration']).sum().reset_index()\n",
        "    return df_prov.to_json('graph_performance_student_list.json',force_ascii=False,orient='records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGHrISEE_B3_"
      },
      "source": [
        "##3. Funções\n",
        "<a id='funcoes'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfuZ_xuiCAjd"
      },
      "source": [
        "### 3.1 Funções de Consulta e Transformação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8k5ZIKXkEJ_"
      },
      "source": [
        "Função de leitura de arquivos txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgY9TfQvkCSh"
      },
      "source": [
        "def read_txt(path):\n",
        "  with open(path,'r') as file:\n",
        "    return file.read() "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aRrmnVXkm82"
      },
      "source": [
        "Função de consulta no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BueEgapukKO8"
      },
      "source": [
        "def lop_consult(url):\n",
        "  http = urllib3.PoolManager()\n",
        "  req = http.request('GET',url)\n",
        "  if req.status == 200:\n",
        "    return pd.read_json(req.data, orient = 'RECORDS', encoding = 'utf-8').copy()\n",
        "  else: \n",
        "    return False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_SDIJpLayi"
      },
      "source": [
        "Função para obter todas as classes do LoP a partir de uma lista de professores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL2uxEK0X3M"
      },
      "source": [
        "def lop_class(df_teacher = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_teacher se torna desnecessário fazer a requisição de todas os professores, e evitando fazer varias consultas\n",
        "  #Dataframe onde será armazenado todas as turmas\n",
        "  df_class = pd.DataFrame()\n",
        "  if df_teacher.empty == True:\n",
        "    #Formação da url de consulta para saber os professores cadastrados no LoP\n",
        "    url_teacher = endpoint_teacher + key\n",
        "    #Realizando a consulta no LoP\n",
        "    df_teacher = lop_consult(url_teacher)#id, email, name\n",
        "  #O laço faz uma varredura das turmas de cada professor e por fim armazena em um dataframe de turmas\n",
        "  for id_teacher in df_teacher['id']:\n",
        "    #O LoP.v2 foi desenvolvido em 2019, então temos que capturar as turmas entre 2019 e o ano atual\n",
        "    current_year = datetime.now().year\n",
        "    for year in range(2019, current_year + 1):\n",
        "      #Por fim precisamos do semestre que deve ser 1 ou 2\n",
        "      for semester in range(1,3): \n",
        "        try:\n",
        "          #Url de consulta de classes\n",
        "          url_class = endpoint_class + id_teacher + '?year=' + str(year) + '&semester=' + str(semester) + '&key=' + key \n",
        "          #Dataframe provisório necessário para capturar o tamanho e saber quantas turmas esse professor tem que estar associado\n",
        "          df_prov = lop_consult(url_class)\n",
        "          #Inserindo o id do professor no dataframe de turmas\n",
        "          df_prov['id_teacher'] = id_teacher\n",
        "          #Adicionando turmas conforme novas consultas\n",
        "          df_class = df_class.append(df_prov, ignore_index=True).copy()#id, name, code, year, semester, id_teacher\n",
        "        except:\n",
        "          pass\n",
        "  #Renomeando colunas com nomes semelhantes em todos os DF\n",
        "  df_class.rename(columns={'id':'id_class','name':'name_class'}, inplace = True)\n",
        "  return df_class"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVs1I-sChMaS"
      },
      "source": [
        "Função para obter todas as submissões a partir de uma lista de turmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqp3HGeFlKC"
      },
      "source": [
        "def lop_submission(df_class = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_class se torna desnecessário fazer a requisição de todas as turmas usando a função lop_class()\n",
        "  #Dataframe onde serão armazenados todas as submissões \n",
        "  df_submission = pd.DataFrame()  \n",
        "  if df_class.empty == True:\n",
        "    df_class = lop_class()  \n",
        "  #Obtem todas as submissões da lista de turmas passadas\n",
        "  for id_class in df_class['id_class']:\n",
        "    #Url da consulta as submissões\n",
        "    url_submission = endpoint_submission + id_class + '/submission?key=' + key\n",
        "    #Dataframe provisório que vai armazenar o resultado da consulta\n",
        "    df_prov = lop_consult(url_submission)\n",
        "    #Inserindo o id_class no dataframe de consultas\n",
        "    df_prov['id_class'] = id_class\n",
        "    #Adicionando submissões conforme consultas\n",
        "    df_submission = df_submission.append(df_prov, ignore_index=True).copy()\n",
        "  #Campo user trás matricula e o nome do usuário, vamos separar em 2 colunas distintas\n",
        "  df_submission[['user','registration']] = df_submission['user'].str.split('-',expand=True)\n",
        "  return df_submission"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPYJVKnjA8jn"
      },
      "source": [
        "Função para obter dados das questões cadastradas no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZu9CVgtA70_"
      },
      "source": [
        "def lop_question():\n",
        "  url_question = endpoint_question + key\n",
        "  df_lop_question = lop_consult(url_question)\n",
        "  df_lop_question.rename(columns = {'id':'id_question','title':'question'}, inplace = True)\n",
        "  return df_lop_question"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBdYtwVOXdZ"
      },
      "source": [
        "Função que transforma os dados das questões extraídas do LoP, assim podemos saber a dificuldade de uma questão, que pode estar associada a uma ou mais listas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3pLjztaOWzR"
      },
      "source": [
        "def question_data(df_question = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_question se torna desnecessário fazer a requisição de todas as turmas usando a função lop_question()\n",
        "  #Dataframes onde serão armazenados todas as questões transformadas\n",
        "  df_list_data = pd.DataFrame() \n",
        "  df_test_data = pd.DataFrame() \n",
        "  df_tag_data = pd.DataFrame()  \n",
        "  df_question_data = pd.DataFrame()  \n",
        "  #i=0\n",
        "  if df_question.empty == True:\n",
        "    df_question = lop_question()\n",
        "  for question,lists,tests,tags,difficulty in zip(df_question['question'],df_question['lists'],df_question['tests'],df_question['tags'],df_question['difficulty']):\n",
        "    #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "    df_prov_lists  = pd.DataFrame(json.loads(str(lists).replace(\"'\",'\"')))\n",
        "    #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "    df_prov_tests  = pd.DataFrame(json.loads(str(tests).replace(\"'\",'\"')))\n",
        "    #df_prov_lists.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_lists['question'] = question\n",
        "    df_prov_lists['difficulty'] = difficulty\n",
        "    df_list_data = df_list_data.append(df_prov_lists, ignore_index = True).copy()\n",
        "    #print(df_list_data['question'])\n",
        "    #print(\"numero de questoes unicas no df \",len(df_list_data['question'].unique()))\n",
        "    df_prov_tests['question'] = question\n",
        "    df_prov_tests['difficulty'] = difficulty\n",
        "    df_test_data = df_test_data.append(df_prov_tests, ignore_index = True).copy()\n",
        "    #Extraindo as tags, que vão dizer o conteudo associado\n",
        "    df_prov_tags = pd.DataFrame(json.loads(str(tags).replace(\"'\",'\"'))).T\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_tags['question'] = question    \n",
        "    df_tag_data = df_tag_data.append(df_prov_tags, ignore_index = True).copy()\n",
        "    #print(i,' ------------------  ',question, ' ',difficulty)\n",
        "    #i+=1\n",
        "    #if i == 100:\n",
        "    #  break\n",
        "  \n",
        "  df_list_data.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "  df_test_data.rename(columns = {'id':'id_test','title':'test'}, inplace = True)\n",
        "  #print(len(df_list_data['question'].unique()))\n",
        "  #df_list_data['difficulty'] = df_list_data['difficulty'].astype('int')\n",
        "  columns_tags = ['question']\n",
        "  for i in range(len(df_tag_data.columns)-1): columns_tags.append('tag'+str(i+1))\n",
        "  df_tag_data.columns = columns_tags\n",
        "  df_list_data = pd.merge(df_list_data, df_tag_data, on = 'question', how = 'outer')#.fillna(0)\n",
        "  df_test_data = pd.merge(df_test_data, df_tag_data, on = 'question', how = 'outer')#.fillna(0)\n",
        "  return  pd.concat([df_list_data, df_test_data],axis=0).copy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tozn2zf9BiSo"
      },
      "source": [
        "Lista de questões selecionadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2N6QbHL9M1U"
      },
      "source": [
        "listas_escolhidas = ['Laboratório 01 - Expressões Aritméticas',\n",
        "\n",
        "'Aula - Introdução Expressões Aritiméticas',\n",
        "\n",
        "'Aula - Funções Aritméticas',\n",
        "\n",
        "'Treinamento - Expressões Aritméticas',\n",
        "\n",
        "'(Lop) Lista de Laboratório 2 - Estrutura de decisão',\n",
        "\n",
        "'(Lop) Estruturas de decisão - problemas sobre divisibilidade',\n",
        "\n",
        "'(Lop) Estruturas de decisão - Múltiplas decisões',\n",
        "\n",
        "'(Lop) Estruturas de decisão - Operadores Lógicos',\n",
        "\n",
        "'Repetição condicional - Lista Resolvida (LOP)',\n",
        "\n",
        "'Repetição condicional - Lista Prática (LOP)',\n",
        "\n",
        "'Repetição condicional - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Repetição contada - Lista Resolvida (LOP)',\n",
        "\n",
        "'Repetição contada - Lista Prática (LOP)',\n",
        "\n",
        "'Repetição contada - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Vetores - Lista Resolvida (LOP)',\n",
        "\n",
        "'Vetores - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Vetores - Lista Prática (LOP)']\n",
        "\n",
        "provas_escolhidas = ['Prova LoP - Turma 05 - 2020.6']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVdq9H1_BD_Q"
      },
      "source": [
        "Função criada para selecionar questões específicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSAX-RVKBJ4T"
      },
      "source": [
        "def select_questions(df_question_data,listas_escolhidas,provas_escolhidas):\n",
        "  #Selecionando onde List não é NaN\n",
        "  df_prov1 = df_question_data.dropna(subset=['list'])#.fillna(0)\n",
        "  #Selecionando onde Test não é NaN\n",
        "  df_prov2 = df_question_data.dropna(subset=['test'])#.fillna(0)\n",
        "  #Concatenação para permitir um loc que busque em todas as instancias\n",
        "  pat1 = '|'.join(['({})'.format(re.escape(c)) for c in listas_escolhidas])\n",
        "  pat2 = '|'.join(['({})'.format(re.escape(c)) for c in provas_escolhidas])\n",
        "  #Busca\n",
        "  df_prov1 = df_prov1.loc[df_prov1['list'].str.contains(pat1)].copy()\n",
        "  df_prov2 = df_prov2.loc[df_prov2['test'].str.contains(pat2)].copy()\n",
        "  return pd.concat([df_prov1, df_prov2],axis=0).copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU4EIevUPzqH"
      },
      "source": [
        "Função para avaliar a perfomance por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B0Kx6BKPfK6"
      },
      "source": [
        "def performance_list(df_submission, df_question_data = pd.DataFrame()):  \n",
        "  #Essa função necessita receber as submissões de uma turma ---------- depois podemos incrementar essa função ao ter uma turma associada e agrupar por elas\n",
        "  #Me traz as porcentagens maximas de acerto por questão\n",
        "  df_performance_list = df_submission.groupby(['user','registration','list','question'])['hitPercentage'].max().reset_index()\n",
        "  #Soma as porcentagens de uma lista unica\n",
        "  df_performance_list = df_performance_list.groupby(['user','registration','list'])['hitPercentage'].sum().reset_index()\n",
        "  #Renomeando para melhorar entendimento\n",
        "  df_performance_list.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
        "  if df_question_data.empty == True:\n",
        "    #Usando a função de dados de questão para ter informações sobre que questões estão associadas a lista\n",
        "    df_question_data = question_data()\n",
        "  #Agrupa por lista e questão para ter apenas uma questão de cada, a operação não importa muito, apenas existe para completar o agrupamento --------- pode ser uma boa trocar por drop_duplicates\n",
        "  df_question_data = df_question_data.groupby(['list','question'])['id_list'].count().reset_index()\n",
        "  #Conta quantas questões tem por lista\n",
        "  df_question_data = df_question_data.groupby(['list'])['question'].count().reset_index()\n",
        "  #Renomeando lista\n",
        "  df_question_data.rename(columns={'question':'totalQuestionsList'}, inplace = True)\n",
        "  #Merge\n",
        "  df_performance_list = df_performance_list.merge(df_question_data, on = 'list')\n",
        "  #Média de acerto por lista\n",
        "  df_performance_list['mediaList'] = df_performance_list['totalHitPercentage'] / df_performance_list['totalQuestionsList']\n",
        "  return df_performance_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLsWhEZ2CIr_"
      },
      "source": [
        "### 3.2 Funções de Gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7lq048T5cvn"
      },
      "source": [
        "Função do gráfico de barras que, por lista, faz a contagem de quem fez mais e menos de X% da lista. Necessita de passar a performance do aluno por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btbzysrv5cF6"
      },
      "source": [
        "def graph_more_less_list_class(df_performance_list,value = 70.0):#value == 70 ou outro numero\n",
        "  #Aqui eu conto, por lista, quantos tiraram mais de 70% de acerto\n",
        "  df_more = df_performance_list[df_performance_list['mediaList'] >= value].groupby('list')['mediaList'].count().reset_index(name='more')\n",
        "  #E nesse conta quantos tiveram menos de 70%\n",
        "  df_less = df_performance_list[df_performance_list['mediaList'] < value].groupby('list')['mediaList'].count().reset_index(name='less')\n",
        "  #Aqui junta ambos os dataframes, usando o outer, que, se por acaso não tiver uma ocorrência de uma lista em um dos dataframes, mesmo assim eles vão ser adicionados, é união dos conjuntos\n",
        "  df_less_more = pd.merge(df_more, df_less, on = 'list', how = 'outer')\n",
        "  #E, se caso acontecer a situação de um não existir, substituimos o nan por 0\n",
        "  df_less_more.replace(np.NaN, 0, inplace = True)\n",
        "  return df_less_more.to_json('graph_more_less_list_class.json',force_ascii=False, orient='records') ############# por hora essa função tamebm esta realizando downlaod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihcn9Bn9QSFy"
      },
      "source": [
        "Esse codigo tem como objetivo transformar uma coluna que tenha varias categorias em uma para cada, e associar a este campo um valor de outra coluna que era correspondente. Por exemplo,\n",
        "\n",
        "user - list - mediaList\n",
        "\n",
        "joao - abcd - 9.8\n",
        "\n",
        "jony - efcg - 5.9\n",
        "\n",
        "para:\n",
        "\n",
        "user - abcd - efcg \n",
        "\n",
        "joao - 9.8  - 0/nan\n",
        "\n",
        "jony - 0/nan - 5.9 \n",
        "\n",
        "Assim, ele necessita receber a **column** que será criada o dummie, e o **value**, que será o valor associado a nova coluna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQshilmiJiLz"
      },
      "source": [
        "'''\n",
        "#Usando dummies para transformar cada lista em uma coluna. O Dummies vai inserir 1 em cada ocorrencia\n",
        "df = pd.get_dummies(df,columns=['list'],prefix='',prefix_sep='')\n",
        "#Cria um dataframe provisório\n",
        "df_prov = pd.DataFrame()\n",
        "#Campo do valor que irei inserir\n",
        "df_mediaList = df['mediaList']\n",
        "#Apagando colunas desnecessárias\n",
        "df = df.drop(columns=['totalHitPercentage','totalQuestionsList','mediaList'])\n",
        "#Iterando sobre todo as submissões\n",
        "for i in range(len(df.user)):\n",
        "  #Substituindo o 1 do dummies pela média da lista\n",
        "  df_prov = df_prov.append(df.iloc[i,:].replace(1,df_mediaList[i]))\n",
        "#Agrupando para todas as linhas se tornarem apenas 1 ocorrência de cada aluno\n",
        "df_prov = df_prov.groupby(['user','registration']).sum().reset_index()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPsbzu40jktx"
      },
      "source": [
        "Função do gráfico de barras que, por aluno, calcula a média do aluno por lista "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwAFPTBAjkeE"
      },
      "source": [
        "def graph_performance_student_list(df_performance_list):\n",
        "  return df_performance_list.sort_values(by='user').drop(columns=['totalHitPercentage','totalQuestionsList']).to_json('graph_performance_student_list.json',force_ascii=False,orient='records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibCTW9blyG0b"
      },
      "source": [
        "Função do grafico de distribuição de notas por lista. Necessita da performance em uma lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmX_TtzQALyR"
      },
      "source": [
        "def graph_distribution_notes_list(df_performance_list):\n",
        "  #Agrupa por lista, e conta as ocorrências\n",
        "  return df_performance_list.groupby('list')['mediaList'].apply(lambda group: group.values.tolist()).to_json('df_distribuition_notes_list.json',force_ascii=False,orient='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnKD95YdJV6Z"
      },
      "source": [
        "Não mexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0MOygqJXNa"
      },
      "source": [
        "#df_teste.groupby('user')[['list','mediaList']].apply(lambda group: group.values.tolist()).to_json(force_ascii=False).replace('{\"','{\"students\":[{\"user\":\"').replace(\":[[\",',\"lists\":[{\"list\":').replace(\":]],\",',\"lists\":}]').replace(']],\"','}],\"user\":\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqHcj6rDyulr"
      },
      "source": [
        "### FUNÇÕES DUPLAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9_1bbECyxjn"
      },
      "source": [
        "Por hora não vou mexer nas outras afim de preservar diante algum bug. As novas com duplas função prova/lista vão ficar aqui por hora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuyVGOpc1JXv"
      },
      "source": [
        "Função para avaliar a performance em uma lista ou prova. Necessita receber agora um label que informa se 'list' ou 'test'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTHMN3agyw-R"
      },
      "source": [
        "def performance_list_test(df_submission, df_question_data = pd.DataFrame(),listORtest = ['list']):  \r\n",
        "  #Essa função necessita receber as submissões de uma turma ---------- depois podemos incrementar essa função ao ter uma turma associada e agrupar por elas\r\n",
        "  #Me traz as porcentagens maximas de acerto por questão\r\n",
        "  df_performance = df_submission.groupby(['user','registration',listORtest,'question'])['hitPercentage'].max().reset_index()\r\n",
        "  #Soma as porcentagens de uma lista/prova unica\r\n",
        "  df_performance = df_performance.groupby(['user','registration',listORtest])['hitPercentage'].sum().reset_index()\r\n",
        "  #Renomeando para melhorar entendimento\r\n",
        "  df_performance.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\r\n",
        "  if df_question_data.empty == True:\r\n",
        "    #Usando a função de dados de questão para ter informações sobre que questões estão associadas a lista\r\n",
        "    df_question_data = question_data()\r\n",
        "  #Agrupa por lista e questão para ter apenas uma questão de cada, a operação não importa muito, apenas existe para completar o agrupamento --------- pode ser uma boa trocar por drop_duplicates\r\n",
        "  df_question_data = df_question_data.groupby([listORtest,'question'])['id_'+listORtest].count().reset_index()\r\n",
        "  #Conta quantas questões tem por lista\r\n",
        "  df_question_data = df_question_data.groupby([listORtest])['question'].count().reset_index()\r\n",
        "  #Renomeando lista\r\n",
        "  df_question_data.rename(columns={'question':'totalQuestions'+listORtest}, inplace = True)\r\n",
        "  #Merge\r\n",
        "  df_performance = df_performance.merge(df_question_data, on = listORtest)\r\n",
        "  #Média de acerto por lista\r\n",
        "  df_performance['media'+listORtest] = df_performance['totalHitPercentage'] / df_performance['totalQuestions'+listORtest]\r\n",
        "  return df_performance"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKN0Qb6F1An-"
      },
      "source": [
        "Função do gráfico de barras que, por lista, faz a contagem de quem fez mais e menos de X% da lista. Necessita de passar a performance do aluno por lista/prova e receber agora um label que informa se 'list' ou 'test'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Se5qIb07gJ"
      },
      "source": [
        "def graph_more_less_list_class(df_performance_list_test,df_class,value = 70.0,listORtest = ['list']):#value == 70 ou outro numero\r\n",
        "  #Aqui eu conto, por lista, quantos tiraram mais de % de acerto escolhida\r\n",
        "  df_more = df_performance_list_test[df_performance_list_test['media'+listORtest] >= value].groupby(listORtest)['media'+listORtest].count().reset_index(name='more')\r\n",
        "  #E nesse conta quantos tiveram menos da % escolhida\r\n",
        "  df_less = df_performance_list_test[df_performance_list_test['media'+listORtest] < value].groupby(listORtest)['media'+listORtest].count().reset_index(name='less')\r\n",
        "  #Aqui junta ambos os dataframes, usando o outer, que, se por acaso não tiver uma ocorrência de uma lista em um dos dataframes, mesmo assim eles vão ser adicionados, é união dos conjuntos\r\n",
        "  df_less_more = pd.merge(df_more, df_less, on = listORtest, how = 'outer')\r\n",
        "  #E, se caso acontecer a situação de um não existir, substituimos o nan por 0\r\n",
        "  df_less_more.replace(np.NaN, 0, inplace = True)\r\n",
        "  #Total de alunos na turma\r\n",
        "  total = df_class.loc[df_class['id_class'] == turma[0],'studentsCount'].max()\r\n",
        "  df_less_more['missing'] = total - (df_less_more['more'] + df_less_more['less'])\r\n",
        "  return df_less_more#.to_json('graph_more_less_'+listORtest+'_class.json',force_ascii=False, orient='records') ############# por hora essa função tamebm esta realizando downlaod"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6CPk_dAAUCE"
      },
      "source": [
        "Função do gráfico de barras que, por aluno, calcula a média do aluno por lista/prova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NOnpIL-APTc"
      },
      "source": [
        "def graph_performance_student_list_test(df_performance_list_test,listORtest = ['list']):\r\n",
        "  return df_performance_list_test.sort_values(by='user').drop(columns=['totalHitPercentage','totalQuestions'+listORtest])#.to_json('graph_performance_student_'+listORtest+'.json',force_ascii=False,orient='records')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaGpFuLmJC70"
      },
      "source": [
        "Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhAmMuJ0A_Yk"
      },
      "source": [
        "turma = ['f2dd7bef-5b5d-4cb3-9efa-aa8652af0605']\n",
        "df_subs = lop_submission(pd.DataFrame(turma, columns = ['id_class']))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDhMM22wlkys"
      },
      "source": [
        "df_class = lop_class()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p86uLtmw6Zn"
      },
      "source": [
        "df_question_data = question_data()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQfvgvO669Ur"
      },
      "source": [
        "df_performance_list = performance_list_test(df_subs, df_question_data,'list')\r\n",
        "df_performance_test = performance_list_test(df_subs, df_question_data,'test')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFCLarsPIwkO",
        "outputId": "af4d09f0-ff6b-4882-9774-98217924503c"
      },
      "source": [
        "df_class.loc[df_class['id_class'] == turma[0],'studentsCount'].max()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzBGGnhX8oAm"
      },
      "source": [
        "df_performance_list.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oymqDAw9u3q"
      },
      "source": [
        "df_performance_test.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfbilnAa-lhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "7c7b85c9-39ca-4305-ee20-4181994c0ce0"
      },
      "source": [
        "graph_more_less_list_class(df_performance_list,df_class,70.0,'list').head(2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>list</th>\n",
              "      <th>more</th>\n",
              "      <th>less</th>\n",
              "      <th>missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Lop) Estruturas de decisão - Múltiplas decisões</td>\n",
              "      <td>36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(Lop) Estruturas de decisão - Operadores Lógicos</td>\n",
              "      <td>33</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               list  more  less  missing\n",
              "0  (Lop) Estruturas de decisão - Múltiplas decisões    36   0.0     86.0\n",
              "1  (Lop) Estruturas de decisão - Operadores Lógicos    33   2.0     87.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YomnnEr_J4Y"
      },
      "source": [
        "graph_more_less_list_class(df_performance_test,df_class,70.0,'test')#.head(2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S6BqVkwBjx4"
      },
      "source": [
        "graph_performance_student_list_test(df_performance_list,'list').head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0zDrfJ0B0LP"
      },
      "source": [
        "graph_performance_student_list_test(df_performance_test,'test').head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-c027W5B8Kz"
      },
      "source": [
        "graph_performance_student_list_test(df_performance_list,'list')\r\n",
        "graph_performance_student_list_test(df_performance_test,'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhyqWE_Xx4EF",
        "outputId": "621e385d-ac7c-4edd-d126-33ebf5d03f18"
      },
      "source": [
        "len(df_subs['registration'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BUSGqrsC9BC"
      },
      "source": [
        "**Por hora descondirem essa função**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gXGYd0w_GRp"
      },
      "source": [
        "'''\n",
        "def avaliar_modelos(df, hyperparameters):\n",
        "\n",
        "  #Dicionários\n",
        "  model_param_disciplinas = {}\n",
        "  best_acc_disciplinas = {}\n",
        "  scoring_disciplinas = {}\n",
        "  #feature_importances_disciplinas = {}\n",
        "\n",
        "  #Seleciona o codigo de cada disciplina no dataframe, --alteravel--\n",
        "  lista_disciplinas = df[\"disciplina\"].unique()  \n",
        "\n",
        "  #Verifica se esta vazio\n",
        "  if lista_disciplinas is None:\n",
        "\t  return None\n",
        "\n",
        "  #Convertendo categorias do target de string para numerico (0,1)\n",
        "  df[\"situacao_categoria\"] = pd.Categorical(df[\"situacao\"]).codes\n",
        "\n",
        "  #Pipeline para transformar em categoria e verificar melhores parametros\n",
        "  pipeline_transform = Pipeline(steps = [('num_pipeline', NumericalTransformer()),\n",
        "                                         ('fs',SelectKBest(chi2)),\n",
        "                                         ('sc',StandardScaler()),\n",
        "                                         ('clf',XGBClassifier())\n",
        "                               ])\n",
        "\n",
        "  #Grid para testar todos os parâmetros                               \n",
        "  grid_search = GridSearchCV(\n",
        "                          estimator = pipeline_transform, \n",
        "                          param_grid = hyperparameters,\n",
        "                          cv= 5,\n",
        "                          scoring = {'Accuracy': make_scorer(accuracy_score)},\n",
        "                          #scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score), \"F1\":\"f1\", \"Recall\":\"recall\", \"Precision\":\"precision\"},\n",
        "                          return_train_score=True,\n",
        "                          n_jobs=-1,#indica o numero de processos em paralelo, -1 significa usar todos\n",
        "                          refit='Accuracy')\n",
        "\n",
        "\n",
        "  #itera sobre a lista de disciplinas\n",
        "  for disciplina in lista_disciplinas:\n",
        "    data_iter = df.loc[df[\"disciplina\"].str.contains(disciplina),:]\n",
        "    \n",
        "    #Treinando Grid\n",
        "    best_model = grid_search.fit(data_iter.drop(columns = [\"disciplina\",\"situacao_categoria\"]), data_iter[\"situacao_categoria\"])\n",
        " \n",
        "    #Extraindo informações do treino\n",
        "    param_modelo = best_model.best_params_\n",
        "    model_param_disciplinas[disciplina] = param_modelo['clf']\n",
        "    best_acc_disciplinas[disciplina] = best_model.best_score_\n",
        "\n",
        "    #Resultado de metricas\n",
        "    result = pd.DataFrame(best_model.cv_results_)\n",
        "    result = result[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy','rank_test_Accuracy']].copy()\n",
        "    result[\"std_ratio\"] = result.std_test_Accuracy/result.std_train_Accuracy\n",
        "    result = result.sort_values(by=\"rank_test_Accuracy\",ascending=True)    \n",
        "    scoring_disciplinas[disciplina] = result.iloc[0,:]\n",
        "\n",
        "    #Características mais importantes\n",
        "    #feature_importances_disciplinas[disciplina] = grid.best_estimator_.feature_importances_\n",
        "    \n",
        "    #Salvando modelo\n",
        "    joblib.dump(best_model, 'modelo_' + disciplina + '.pkl')\n",
        "\n",
        "\n",
        "  #Transformando o dicionário para Dataframe\n",
        "  df_best_acc = pd.DataFrame.from_dict(best_acc_disciplinas, orient=\"index\")\n",
        "  df_best_acc.columns = [\"accuracy\"]\n",
        "  df_scor_disc = pd.DataFrame.from_dict(scoring_disciplinas, orient=\"index\")\n",
        "\n",
        "  #Concatenando DataFrames\n",
        "  df_relatorio = pd.concat([df_best_acc, df_scor_disc], axis=1, sort=False)\n",
        "\n",
        "  return (df_relatorio,model_param_disciplinas)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1-lyVuizPA"
      },
      "source": [
        "##4. Leitura da Base\n",
        "<a id='leiturabase'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVMECL1jJAxf"
      },
      "source": [
        "### Foi projetado para ter 4 tipos de consultas\n",
        "\n",
        "* A primeira é para receber dados dos professores que estão resgistrados no sistema\n",
        "\n",
        "* A segunda é para receber dados das turmas que estão registradas no sistema\n",
        "\n",
        "* A terceira é para receber dados das submissões que estão registradas no sistema\n",
        "\n",
        "* A quarta é para receber dados das questões que estão registradas no sistema\n",
        "\n",
        "As consultas vão ser tornando acumulativas, com a segunda dependendo de dados da primeira, e a terceira dependendo de dados da primeira e segunda para o preenchimento da url de consulta. Todas as consultas dependem da key de acesso\n",
        "\n",
        "Na consulta da class possui as depedências de: \n",
        "1. id_teacher, que é o id de um professor\n",
        "2. year, que é o ano da turma \n",
        "3. semester, que é o semestre (1 ou 2) da turma\n",
        "\n",
        "E na consulta de submission necessita do:\n",
        "1. id_class, que é o id de uma turma.\n",
        "\n",
        "Já a consulta de question e do teacher necessita apenas da key\n",
        "\n",
        "As consultas serão feitas via protocolo HTTP usando o método Get e irão receber um JSON dos dados do LoP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2rVvODlKxFz"
      },
      "source": [
        "### Estrutra das funções e suas dependências\n",
        "\n",
        "Funções de coleta e transformações de dados \n",
        "\n",
        "- lop_class(), lop_question()\n",
        "--- lop_submission()\n",
        "------ question_data()\n",
        "--------- performance_list()\n",
        "------------ graph_more_less_70_list_class()\n",
        "------------ graph_distribution_notes_list()\n",
        "\n",
        "Funções de treinamento de modelos de Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLS4lxbbQwTo"
      },
      "source": [
        "Leitura de endpoints e key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syfUfm4xQz82"
      },
      "source": [
        "key = read_txt('key.txt')\n",
        "endpoint_teacher = read_txt('endpoint_teacher.txt')\n",
        "endpoint_class = read_txt('endpoint_class.txt')\n",
        "endpoint_submission = read_txt('endpoint_submission.txt')\n",
        "endpoint_question = read_txt('endpoint_question.txt')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8EDgPstkv9e"
      },
      "source": [
        "Consultando submissões a partir de uma lista de turmas\n",
        "\n",
        "Vou pegar uma turma aleatoria afim de montar uma consulta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCJzm_YXlwJo"
      },
      "source": [
        "turma = ['f2dd7bef-5b5d-4cb3-9efa-aa8652af0605']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBVlqgzZmWN1"
      },
      "source": [
        "Necessita passar como DataFrame, então eu vou construir nesse formato exibido abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEUmG7bRl-jn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c12a5992-80b6-4ce5-ed1e-aa79f746a40a"
      },
      "source": [
        "pd.DataFrame(['b5413cd7-4f61-4241-aad8-23740bab604f'], columns = ['id_class']).to_json(orient='records')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[{\"id_class\":\"b5413cd7-4f61-4241-aad8-23740bab604f\"}]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuA_GGParVFn"
      },
      "source": [
        "**A partir daqui ainda vai sofrer alterações**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hra4Ho4IC0Xu"
      },
      "source": [
        "#Parte III - Desenvolvimento\n",
        "<a id='enten_dados'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n4co8p2EeaU"
      },
      "source": [
        "## 1. Entendimento de Dados\n",
        "<a id='enten_dados'></a>\n",
        "\n",
        "### [1.1 Descrição de Dados](#descricao)\n",
        "### [1.2 Qualidade de Dados](#qualidade)\n",
        "### [1.3 Exploração de Dados](#exploracao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEVg1VCYEhUd"
      },
      "source": [
        "###1.1 Descrição de Dados\n",
        "<a id='descricao'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1HZgOL4pQfu"
      },
      "source": [
        "#### <center>Dataframe Submissões\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyy |\n",
        "| 2020.6 | yyyy | xxx |\n",
        "\n",
        "#### <center>Dataframe Resultados em LOP\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyyyy |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do datafrane dos professores - Consulta embutida em lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. email</b> Email do professor\n",
        "\n",
        "<b>3. name_teacher</b> Nome do professor\n",
        "\n",
        "--- \n",
        "\n",
        "####Descrição do dataframe das turmas - lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. id_class</b> ID da turma\n",
        "\n",
        "<b>3. name_class</b> Nome da turma\n",
        "\n",
        "<b>4. code</b> Código de acesso a turma no LoP\n",
        "\n",
        "<b>5. year</b> Ano em que a turma foi cadastrada\n",
        "\n",
        "<b>6. semester</b> Semestre em que a turma foi cadastrada\n",
        "\n",
        "---\n",
        "####Descrição dos dataframe de Submissão - lop_submission()\n",
        "\n",
        "\n",
        "<b>1. environment</b> Tipo de máquina\n",
        "\n",
        "<b>2. hitPercentage</b> Porcentagem de acerto na questão\n",
        "\n",
        "<b>3. language</b> Linguagem de programação usada\n",
        "\n",
        "<b>4. char_change_number</b> Número de caracteres alterados\n",
        "\n",
        "<b>5. timeConsuming</b> Tempo que passou na questão\n",
        "\n",
        "<b>6. createdAt</b> Data e hora da submissão\n",
        "\n",
        "<b>7. user</b> Nome do aluno\n",
        "\n",
        "<b>8. question</b> Nome da questão\n",
        "\n",
        "<b>9. list</b> Nome da lista\n",
        "\n",
        "<b>10. test</b> Nome da prova\n",
        "\n",
        "<b>11. id_class</b> ID da turma em que o aluno está associado nessa submissão\n",
        "\n",
        "<b>12. registration</b> Matrícula do aluno\n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do dataframe das questões do LoP - lop_question()\n",
        "\n",
        "\n",
        "<b>1. id_questao</b> ID da questão\n",
        "\n",
        "<b>2. question</b> Nome da questão\n",
        "\n",
        "<b>3. difficulty </b> Nível de dificuldade da questão (1-5)\n",
        "\n",
        "<b>4. tags </b> Esse campo vem com um json que contem os assuntos em que essa questão está associada\n",
        "\n",
        "<b>5. lists </b> Esse campo vem com um json que contem as listas que a questão está associada \n",
        "\n",
        "<b>6. tests</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---\n",
        "\n",
        "####Descrição do dataframe de dados das questões - question_data()\n",
        "\n",
        "\n",
        "<b>1. id_list</b> ID da lista\n",
        "\n",
        "<b>2. list</b> Nome da lista\n",
        "\n",
        "<b>3. question </b> Nome da questão\n",
        "\n",
        "<b>4. difficulty </b> Nível de dificuldade da questão (0-5)\n",
        "\n",
        "<b>5. tags </b> Em cada coluna com nome tag, terá um conteúdo associado a ela\n",
        "\n",
        "<b>6. id_test</b> ID da prova\n",
        "\n",
        "<b>7. test</b> Nome da prova\n",
        "\t\n",
        "---\n",
        "\n",
        "\n",
        "####Descrição do dataframe de performance por lista - performance_list_test()\n",
        "\n",
        "\n",
        "<b>1. user</b> Nome do aluno\n",
        "\n",
        "<b>2. registration</b> Matrícula do aluno\n",
        "\n",
        "<b>3. list/test</b> Nome da lista/prova\n",
        "\n",
        "<b>4. totalHitPercentage </b> Soma de todos acertos de questões únicas\n",
        "\n",
        "<b>5. totalQuestionslist/test </b> Número de questões por lista/prova\n",
        "\n",
        "<b>6. medialist/test</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkk0NKmUpeX8"
      },
      "source": [
        "#### Nomeclaturas e especificações dos gráficos \n",
        "\n",
        "<b>1. GTN </b> Grafico de Turma Nota \n",
        "\n",
        "<b>1. GTL </b> Grafico de Turma Lista\n",
        "\n",
        "<b>1. GTA </b> Grafico de Turma Assunto\n",
        "\n",
        "<b>2. GENL </b> Grafico de Estudante Nota Lista\n",
        "\n",
        "<b>2. GENA </b> Grafico de Estudante Nota Assunto\n",
        "\n",
        "<b>2. GEND </b> Grafico de Estudante Nota Dificuldade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBAPloS58yP"
      },
      "source": [
        "###1.2 Qualidade dos dados\n",
        "<a id='qualidade'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXMGrCW2t9ys"
      },
      "source": [
        "profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlpXzVJfPKL-"
      },
      "source": [
        "df.select_dtypes(include=['int64','float64']).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVjvZp435e2C"
      },
      "source": [
        "Plotando correlação entre os dados númericos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnuyvSq5j_-"
      },
      "source": [
        "corr = df.corr()\n",
        "corr = corr.style.background_gradient(cmap='Blues')\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23glKTxPo98x"
      },
      "source": [
        "Falar um pouco da correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjeHFDBfwV5w"
      },
      "source": [
        "###1.3 Exploração de Dados\n",
        "<a id='exploracao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgJ2UcFYoad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9S1wjjCuu89"
      },
      "source": [
        "##2. Preparação de Dados\n",
        "<a id='preparo'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuPFoSjMvBNL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPh-k3-fR_zP"
      },
      "source": [
        "##3. Métricas de Avaliação\n",
        "<a id='metricas'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXy0iQtzn75"
      },
      "source": [
        "\n",
        "#### <center>Métricas de Avaliação:\n",
        "| Regressores | Classificadores\n",
        "| --- | --- |\n",
        "| <center>RMSE| <center>Matriz de Confusão |\n",
        "| <center>MAE| <center>Acurácia |\n",
        "| <center>R2| <center>Precisão / Recall / F1 |\n",
        "| <center>R2 Ajustado| <center>AUC |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEJF9bZMSZpk"
      },
      "source": [
        "##4. Modelagem\n",
        "<a id='#modelagem'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4zVFwlFZUjt"
      },
      "source": [
        "Dicionário com hiper-parâmetros dos algoritmos preditivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeVjRatU2xs"
      },
      "source": [
        "hyperparameters = [\n",
        "                  {\"clf\":[RandomForestClassifier()],\n",
        "                  \"clf__n_estimators\": [100],\n",
        "                  \"clf__criterion\": [\"entropy\"],\n",
        "                  \"clf__max_leaf_nodes\": [64],\n",
        "                  \"clf__random_state\": [42],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,30]\n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[KNeighborsClassifier()],\n",
        "                  \"clf__n_neighbors\":[5,9,11],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,30]                 \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[SVC()],\n",
        "                  \"clf__kernel\":[\"sigmoid\",'rbf'],\n",
        "                  \"clf__degree\":[3,4],\n",
        "                  \"clf__gamma\":[0.1,0.5,1],\n",
        "                  \"clf__C\":[0.001,1,2],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[4,9,15,25,31] \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[GaussianNB()]\n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[MLPClassifier()],\n",
        "                  \"clf__hidden_layer_sizes\": [(64,),(128,)],\n",
        "                  \"clf__activation\": [\"logistic\"],\n",
        "                  \"clf__solver\": [\"sgd\"],\n",
        "                  \"clf__max_iter\": [500],\n",
        "                  \"clf__early_stopping\":[True],\n",
        "                  \"clf__n_iter_no_change\":[20],\n",
        "                  \"clf__validation_fraction\":[0.20], \n",
        "                  },\n",
        "              \n",
        "                  {\"clf\":[XGBClassifier()],\n",
        "                  \"clf__n_estimators\": [50,100],\n",
        "                  \"clf__max_depth\": [4,6],\n",
        "                  \"clf__learning_rate\": [0.001, 0.01,0.1],\n",
        "                  \"clf__random_state\": [42],\n",
        "                  \"clf__subsample\": [1.0],\n",
        "                  \"clf__colsample_bytree\": [1.0],\n",
        "                  \"fs__score_func\":[chi2],\n",
        "                  \"fs__k\":[5,8,15,25,31]\n",
        "                  }\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4rJ_jPviRsl"
      },
      "source": [
        "##5. Avaliação dos Modelos\n",
        "<a id='avaliacao'></a>\n",
        "\n",
        "### [5.1 Chamada da Função](#chamada)\n",
        "### [5.2 Teste de Modelo](#teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxO10k-KJnZq"
      },
      "source": [
        "###5.1 Chamada da Função\n",
        "<a id='chamada'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a54d338IldVz"
      },
      "source": [
        "(df_relatorio, model_param_disciplinas) = avaliar_modelos(df, hyperparameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgZO6QU0YH1"
      },
      "source": [
        "df_relatorio.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCcRXPWv0eAL"
      },
      "source": [
        "model_param_disciplinas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmuLGrPKFv1c"
      },
      "source": [
        "###5.2 Teste de Modelo\n",
        "<a id='teste'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GMVe3bUsvS"
      },
      "source": [
        "Importando Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchPDLEsUvt5"
      },
      "source": [
        "modelo_teste = joblib.load('modelo_.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lcNJROjYtth"
      },
      "source": [
        "Aplicando a transformação no teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgKRWABoBfVb"
      },
      "source": [
        "num_transf = NumericalTransformer()\n",
        "df_teste = model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jte7qW39ZR8V"
      },
      "source": [
        "df_teste.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Qb55Di8IkC"
      },
      "source": [
        "Realizando teste de um modelo, prevendo probabilidade de ser aprovado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLooF6-vaQ7C"
      },
      "source": [
        "df_teste.iloc[42,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zusMtVzabUZ"
      },
      "source": [
        "df_teste.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTg3Zgf-YrEm"
      },
      "source": [
        "modelo_teste.predict(df_teste.iloc[42,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGR1IWltjEKS"
      },
      "source": [
        "##6. Conclusão e Recomendações\n",
        "<a id='conclusao'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-JlYcDhvmg4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bW-MMNpvndY"
      },
      "source": [
        "##7. Implantação de Modelos\n",
        "<a id='implantacao'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARXhhB39jAMp"
      },
      "source": [
        "Modelo de Json para resposta da API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bcNUiIDvzTt"
      },
      "source": [
        "{\n",
        "\"graph1\": [\n",
        "     {\n",
        "        \"list\": \"IMD0012 - 2020.6: Lista Obrigatória, Semana 1\",\n",
        "        \"more70\": 27.0,\n",
        "        \"less70\": 8\n",
        "     },\n",
        "  ],\n",
        "\"graph2\": [\n",
        "      {\n",
        "        \"user\": \"Adailton Aquino dos Santos \",\n",
        "        \"registration\": \" 20180070994\",\n",
        "        \"IMD0012 - 2020.6: Lista Obrigatória, Semana 1\": 0.0,\n",
        "        \"IMD0012 - 2020.6: Lista Preparatória, Semana 3\": 0.0,\n",
        "        \"ITP - Alocação dinâmica\": 0.0,\n",
        "        \"ITP - Funções - Lista\": 0.0,\n",
        "         ...\n",
        "      },\n",
        "  ],\n",
        "}\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}